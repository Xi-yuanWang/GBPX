{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38664bittorchgeoconda6f756dd914a64c5bbfcc12322cd6a319",
   "display_name": "Python 3.8.6 64-bit ('torch_geo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3935435c4970ceab1e1d8d5675c5223ca0053c7b5ef4301f02ab5cfd2d556a50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch_geometric.datasets import CitationFull\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citeseer=CitationFull(\"../data\",\"Citeseer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"./CiteSeer.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias='none'):\n",
    "        super(Dense, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias == 'bn':\n",
    "            self.bias = nn.BatchNorm1d(out_features)\n",
    "        else:\n",
    "            self.bias = lambda x: x\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = torch.mm(input, self.weight)\n",
    "        output = self.bias(output)\n",
    "        # 跳层连接\n",
    "        if self.in_features == self.out_features:#??\n",
    "            output = output + input\n",
    "        return output\n",
    "\n",
    "class GnnBP(nn.Module):\n",
    "    def __init__(self, nfeat, nlayers,nhidden, nclass, dropout, bias):\n",
    "        super(GnnBP, self).__init__()\n",
    "        self.fcs = nn.ModuleList()\n",
    "        self.fcs.append(Dense(nfeat, nhidden, bias))\n",
    "        for _ in range(nlayers-2):\n",
    "            self.fcs.append(Dense(nhidden, nhidden, bias))\n",
    "        self.fcs.append(Dense(nhidden, nclass))\n",
    "        self.act_fn = nn.ReLU()\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.act_fn(self.fcs[0](x))\n",
    "        for fc in self.fcs[1:-1]:\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.act_fn(fc(x))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.fcs[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GnnBP(nfeat=X.shape[1],\n",
    "            nlayers=2,\n",
    "            nhidden=64,\n",
    "            nclass=6,\n",
    "            dropout=0.5,\n",
    "            bias = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt=[]\n",
    "yset=set([i.item() for i in Citeseer.data.y])\n",
    "for y in yset:\n",
    "    for i in range(40):\n",
    "        t=np.random.randint(0,X.shape[0])\n",
    "        while(Citeseer.data.y[t].item()!=y):\n",
    "            t=np.random.randint(0,X.shape[0])\n",
    "        Vt.append(t)\n",
    "Vv=[i for i in range(X.shape[0]) if i not in Vt]\n",
    "trainX=X[Vt]\n",
    "testX=X[Vv]\n",
    "trainY=Citeseer.data.y[Vt]\n",
    "testY=Citeseer.data.y[Vv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, \n",
    "    weight_decay=5e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    time_epoch = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss_train = loss_fn(output, batch_y)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        time_epoch+=(time.time()-t1)\n",
    "        loss_list.append(loss_train.item())\n",
    "    return np.mean(loss_list),time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def muticlass_f1(output, labels):\n",
    "    preds = output.max(1)[1]\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    micro = f1_score(labels, preds, average='micro')\n",
    "    return micro\n",
    "\n",
    "def mutilabel_f1(y_true, y_pred):\n",
    "    y_pred[y_pred > 0] = 1\n",
    "    y_pred[y_pred <= 0] = 0\n",
    "    return f1_score(y_true, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(torch.Tensor(testX))\n",
    "        micro_val = muticlass_f1(output, testY)\n",
    "        return micro_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVt(size,nV,y):\n",
    "    Vt=[]\n",
    "    yset=set([i.item() for i in Citeseer.data.y])\n",
    "    for y in yset:\n",
    "        for i in range(size):\n",
    "            t=np.random.randint(0,X.shape[0])\n",
    "            while(Citeseer.data.y[t].item()!=y):\n",
    "                t=np.random.randint(0,X.shape[0])\n",
    "            Vt.append(t)\n",
    "    return Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:0050 train loss:0.029 | val acc:0.861 | cost0.089\n",
      "Epoch:0050 train loss:0.160 | val acc:0.866 | cost0.150\n",
      "Epoch:0050 train loss:0.113 | val acc:0.848 | cost0.196\n",
      "Epoch:0050 train loss:0.229 | val acc:0.866 | cost0.273\n",
      "Epoch:0050 train loss:0.194 | val acc:0.845 | cost0.328\n",
      "Epoch:0050 train loss:0.159 | val acc:0.895 | cost0.271\n",
      "Epoch:0050 train loss:0.265 | val acc:0.872 | cost0.417\n",
      "Epoch:0050 train loss:0.163 | val acc:0.876 | cost0.312\n",
      "Epoch:0050 train loss:0.316 | val acc:0.893 | cost0.405\n",
      "Epoch:0050 train loss:0.194 | val acc:0.873 | cost0.389\n",
      "Epoch:0050 train loss:0.225 | val acc:0.881 | cost0.556\n",
      "Epoch:0050 train loss:0.226 | val acc:0.896 | cost0.518\n",
      "Epoch:0050 train loss:0.248 | val acc:0.886 | cost0.647\n",
      "Epoch:0050 train loss:0.202 | val acc:0.887 | cost0.585\n",
      "Epoch:0050 train loss:0.240 | val acc:0.894 | cost0.687\n"
     ]
    }
   ],
   "source": [
    "for size in range(5,80,5):\n",
    "    Vt=getVt(size,Citeseer.data.num_nodes,Citeseer.data.y)\n",
    "    Vv=[i for i in range(X.shape[0]) if i not in Vt]\n",
    "    trainX=X[Vt]\n",
    "    testX=X[Vv]\n",
    "    trainY=Citeseer.data.y[Vt]\n",
    "    testY=Citeseer.data.y[Vv]\n",
    "\n",
    "\n",
    "    torch_dataset = Data.TensorDataset(torch.Tensor(trainX), trainY)\n",
    "    loader = Data.DataLoader(dataset=torch_dataset,\n",
    "                            batch_size=64,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "    train_time=0\n",
    "    for epoch in range(50):\n",
    "        loss_tra,train_ep = train()\n",
    "        f1_val = test()\n",
    "        train_time+=train_ep\n",
    "        if(epoch+1)%50 == 0: \n",
    "                print('Epoch:{:04d}'.format(epoch+1),\n",
    "                    'train',\n",
    "                    'loss:{:.3f}'.format(loss_tra),\n",
    "                    '| val',\n",
    "                    'acc:{:.3f}'.format(f1_val),\n",
    "                    '| cost{:.3f}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}